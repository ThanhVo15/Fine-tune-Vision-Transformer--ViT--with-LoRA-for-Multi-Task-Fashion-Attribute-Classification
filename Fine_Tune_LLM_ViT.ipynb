{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. https://ai.plainenglish.io/understanding-low-rank-adaptation-lora-for-efficient-fine-tuning-of-large-language-models-082d223bb6db\n",
        "2. https://medium.com/@manindersingh120996/practical-guide-to-fine-tune-llms-with-lora-c835a99d7593\n",
        "3. https://medium.com/@imabhi1216/fine-tuning-a-vision-transformer-vit-model-with-a-custom-dataset-37840e4e9268"
      ],
      "metadata": {
        "id": "9yL8nTH9v-Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Pip Install / Load Libraries / Load Dataset form Hugging face"
      ],
      "metadata": {
        "id": "bAuhBBj6wClV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets torchvision accelerate evaluate"
      ],
      "metadata": {
        "id": "e1pT6JggwBNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVM_UoGym1Sc"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "\n",
        "# Lấy thông tin RAM (số byte khả dụng)\n",
        "available_ram = psutil.virtual_memory().available\n",
        "# Lấy số lượng lõi CPU (logical)\n",
        "cpu_count = psutil.cpu_count(logical=True)\n",
        "\n",
        "print(f\"Available RAM: {available_ram / (1024**3):.2f} GB\")\n",
        "print(f\"CPU count: {cpu_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datasets import load_from_disk\n",
        "\n",
        "from datasets import load_dataset, Features, Value\n",
        "from transformers import ViTFeatureExtractor\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "cTgGYeEbwHn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dict  = load_dataset(\"ashraq/fashion-product-images-small\")\n",
        "dataset_dict"
      ],
      "metadata": {
        "id": "ula_bbMDwK2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Basic Preprocessing and Understanding Data"
      ],
      "metadata": {
        "id": "U-Mbdrk5wMrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset_dict[\"train\"]\n",
        "train_dataset_org = dataset_dict[\"train\"]"
      ],
      "metadata": {
        "id": "0YhNUCGOwN5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shown_labels = set()\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Loop through the dataset and plot the first image of each label\n",
        "for i, sample in enumerate(train_dataset):\n",
        "    label = sample[\"masterCategory\"]  # lấy nhãn trực tiếp vì nó đã là chuỗi\n",
        "    if label not in shown_labels:\n",
        "        plt.subplot(1, len(set([s[\"masterCategory\"] for s in train_dataset])), len(shown_labels) + 1)\n",
        "        plt.imshow(sample[\"image\"])\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "        shown_labels.add(label)\n",
        "        # Nếu đã hiển thị hết các nhãn, dừng vòng lặp\n",
        "        if len(shown_labels) == len(set([s[\"masterCategory\"] for s in train_dataset])):\n",
        "            break\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-i2odR9twRaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Add Random Price Column"
      ],
      "metadata": {
        "id": "e6HC2ZPTwZs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_price(masterCategory, subCategory, articleType, year, season, usage):\n",
        "    master_price_range = {\n",
        "        'Apparel': (10, 20), 'Accessories': (5, 100), 'Footwear': (20, 200),\n",
        "        'Personal Care': (5, 300), 'Free Items': (0, 5), 'Sporting Goods': (100, 250), 'Home': (100, 300)\n",
        "    }\n",
        "    sub_price_adjustment = {\n",
        "        'Topwear': (5, 50), 'Watches': (30, 150), 'Shoes': (20, 100),\n",
        "        'Bags': (10, 70), 'Fragrance': (5, 80), 'Jewellery': (10, 200)\n",
        "    }\n",
        "    article_price_range = {\n",
        "        'Shirts': (15, 70), 'Watches': (50, 300), 'Sports Shoes': (40, 200),\n",
        "        'Sunglasses': (30, 150), 'Perfumes': (25, 120)\n",
        "    }\n",
        "\n",
        "    # Lấy khoảng giá từ masterCategory\n",
        "    base_min, base_max = master_price_range.get(masterCategory, (10, 100))\n",
        "\n",
        "    # Điều chỉnh theo subCategory\n",
        "    adj_min, adj_max = sub_price_adjustment.get(subCategory, (0, 0))\n",
        "\n",
        "    # Điều chỉnh theo articleType\n",
        "    art_min, art_max = article_price_range.get(articleType, (base_min + adj_min, base_max + adj_max))\n",
        "\n",
        "    # Điều chỉnh theo năm\n",
        "    if year < 2015:\n",
        "        discount = 0.3\n",
        "    elif year < 2018:\n",
        "        discount = 0.15\n",
        "    else:\n",
        "        discount = 0\n",
        "\n",
        "    final_min = art_min * (1 - discount)\n",
        "    final_max = art_max * (1 - discount)\n",
        "\n",
        "    return round(np.random.uniform(final_min, final_max) * 2500, 0)"
      ],
      "metadata": {
        "id": "x5NIe0IwwRkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_price_column(example):\n",
        "    example[\"price_in_vnd\"] = assign_price(\n",
        "        example[\"masterCategory\"],\n",
        "        example[\"subCategory\"],\n",
        "        example[\"articleType\"],\n",
        "        example[\"year\"],\n",
        "        example[\"season\"],\n",
        "        example[\"usage\"]\n",
        "    )\n",
        "    return example\n"
      ],
      "metadata": {
        "id": "Yc__y4hlwfT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_null(example):\n",
        "    # Kiểm tra xem có giá trị nào trong example bị None không\n",
        "    return any(val is None for val in example.values())\n",
        "\n",
        "missing_null = train_dataset.filter(has_null)\n",
        "print(f\"Số record có giá trị null: {len(missing_null)}\")"
      ],
      "metadata": {
        "id": "O3CR-YHywfr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dict[\"train\"] = dataset_dict[\"train\"].map(add_price_column)\n",
        "# Split the training data into train and test (let's say 10% for the test set)\n",
        "train_test_split = dataset_dict['train'].train_test_split(test_size=0.1, seed = 42)\n",
        "# Further split the training set to get a validation set (e.g., 10% of the training set)\n",
        "train_val_split = train_test_split['train'].train_test_split(test_size=0.1, seed = 42)"
      ],
      "metadata": {
        "id": "842AO9WjwhxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the splits into a new DatasetDict\n",
        "final_dataset = {\n",
        "    'train': train_val_split['train'],\n",
        "    'val': train_val_split['test'],\n",
        "    'test': train_test_split['test']\n",
        "}\n",
        "\n",
        "final_dataset"
      ],
      "metadata": {
        "id": "qNCyNpVcwlD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = final_dataset[\"train\"]\n",
        "val_dataset = final_dataset[\"val\"]\n",
        "test_dataset = final_dataset[\"test\"]"
      ],
      "metadata": {
        "id": "xHkgQOyzwn6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.features"
      ],
      "metadata": {
        "id": "DShZ-ckVwwKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.features import Image\n",
        "features = Features({\n",
        "    'id': Value('int64'),\n",
        "    'gender': Value('string'),\n",
        "    'masterCategory': Value('string'),\n",
        "    'subCategory': Value('string'),\n",
        "    'articleType': Value('string'),\n",
        "    'baseColour': Value('string'),\n",
        "    'season': Value('string'),\n",
        "    'year': Value('int64'),\n",
        "    'usage': Value('string'),\n",
        "    'productDisplayName': Value('string'),\n",
        "    'image': Image(),\n",
        "    'price_in_vnd': Value('int64')\n",
        "})\n"
      ],
      "metadata": {
        "id": "IzMpTlkZwrX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyển đổi dataset với features mới\n",
        "train_dataset = train_dataset.cast(features)\n",
        "val_dataset = val_dataset.cast(features)\n",
        "test_dataset = test_dataset.cast(features)"
      ],
      "metadata": {
        "id": "2SU8bCW2wwu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Define Length in ProductDisplayName"
      ],
      "metadata": {
        "id": "1b0LytWZw12b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df= df.drop(columns= 'token_length')\n",
        "# df.to_csv(r'/home/ailab1/student_share/Thanh/GPU/Data/df_train.csv', index = False)"
      ],
      "metadata": {
        "id": "Qi0dFclMw_I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'/home/ailab1/student_share/Thanh/GPU/Data/df_train.csv')\n",
        "df['token_length'] = df['productDisplayName'].apply(lambda x: len(tokenizer.tokenize(x)))\n"
      ],
      "metadata": {
        "id": "TFgC_ffhw69F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra phân phối độ dài token\n",
        "print(df['token_length'].describe())\n",
        "# Vẽ histogram độ dài tokens\n",
        "plt.hist(df['token_length'], bins=30, color='blue', alpha=0.7)\n",
        "plt.xlabel(\"Số lượng tokens\")\n",
        "plt.ylabel(\"Số dòng dữ liệu\")\n",
        "plt.title(\"Phân phối độ dài token\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kddUIk4Lw9NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(tokenizer.tokenize(text)) for text in df[\"productDisplayName\"]]\n",
        "print(f\"Độ dài trung bình: {np.mean(lengths)}\")\n",
        "print(f\"Độ dài lớn nhất: {np.max(lengths)}\")\n",
        "print(f\"90% mô tả có độ dài dưới: {np.percentile(lengths, 90)} tokens\")\n",
        "print(f\"95% mô tả có độ dài dưới: {np.percentile(lengths, 95)} tokens\")"
      ],
      "metadata": {
        "id": "NZZhq25YxBOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Label Encoder"
      ],
      "metadata": {
        "id": "tfyMpEzTxC3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_brand(name, gender):\n",
        "    # Chuyển đổi sang chữ thường để tìm kiếm không phân biệt hoa thường\n",
        "    name_lower = name.lower()\n",
        "    gender_lower = gender.lower()\n",
        "    # Tách các từ của productDisplayName\n",
        "    tokens = name.split(\" \")\n",
        "    tokens_lower = name_lower.split(\" \")\n",
        "    if gender_lower in tokens_lower:\n",
        "        idx = tokens_lower.index(gender_lower)\n",
        "        brand_tokens = tokens[:idx]  # Lấy tất cả từ trước từ gender\n",
        "        # Tùy chỉnh: Nếu muốn loại bỏ từ \"by\" nếu nằm giữa, có thể xử lý thêm\n",
        "        brand = \" \".join(brand_tokens).replace(\"by\", \"\").strip()\n",
        "        return brand\n",
        "    else:\n",
        "        return tokens[0]"
      ],
      "metadata": {
        "id": "KqMy3mPpxE9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_brand_mapping(dataset):\n",
        "    # Duyệt qua từng productDisplayName và sử dụng cột gender tương ứng\n",
        "    brands = []\n",
        "    for name, gender in zip(dataset[\"productDisplayName\"], dataset[\"gender\"]):\n",
        "        brands.append(extract_brand(name, gender))\n",
        "    unique_brands = sorted(list(set(brands)))\n",
        "    mapping = {brand: idx for idx, brand in enumerate(unique_brands)}\n",
        "    inv_mapping = {idx: brand for brand, idx in mapping.items()}\n",
        "    return mapping, inv_mapping"
      ],
      "metadata": {
        "id": "UKyarf4vxG60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm xây dựng mapping cho một cột\n",
        "def build_mapping(dataset, col):\n",
        "    unique_labels = dataset.unique(col)\n",
        "    unique_labels.sort()  # Sắp xếp để nhất quán (tùy chọn)\n",
        "    mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    inv_mapping = {idx: label for label, idx in mapping.items()}\n",
        "    return mapping, inv_mapping"
      ],
      "metadata": {
        "id": "T9UUzUgRxIys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ví dụ với các cột danh mục:\n",
        "gender_map, inv_gender_map = build_mapping(train_dataset_org, \"gender\")\n",
        "master_category_map, inv_master_category_map = build_mapping(train_dataset_org, \"masterCategory\")\n",
        "sub_category_map, inv_sub_category_map = build_mapping(train_dataset_org, \"subCategory\")\n",
        "article_type_map, inv_article_type_map = build_mapping(train_dataset_org, \"articleType\")\n",
        "base_colour_map, inv_base_colour_map = build_mapping(train_dataset_org, \"baseColour\")\n",
        "usage_map, inv_usage_map = build_mapping(train_dataset_org, \"usage\")\n",
        "brand_map, inv_brand_map = build_brand_mapping(train_dataset_org)\n",
        "\n",
        "# Kiểm tra các mapping:\n",
        "print(\"Gender mapping:\", gender_map)\n",
        "print(\"Master Category mapping:\", master_category_map)\n",
        "print(\"Sub Category mapping:\", sub_category_map)\n",
        "print(\"Article Type mapping:\", article_type_map)\n",
        "print(\"Base Colour mapping:\", base_colour_map)\n",
        "print(\"Usage mapping:\", usage_map)\n",
        "print(\"Brand mapping:\", brand_map)"
      ],
      "metadata": {
        "id": "_EW1W64JxKbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_categorical(example):\n",
        "    # Cập nhật các cột theo mapping đã xây dựng\n",
        "\n",
        "    example[\"masterCategory\"] = master_category_map[example[\"masterCategory\"]]\n",
        "    example[\"subCategory\"] = sub_category_map[example[\"subCategory\"]]\n",
        "    example[\"articleType\"] = article_type_map[example[\"articleType\"]]\n",
        "    example[\"baseColour\"] = base_colour_map[example[\"baseColour\"]]\n",
        "    example[\"usage\"] = usage_map[example[\"usage\"]]\n",
        "\n",
        "    # Nếu dataset của bạn vẫn có cột \"productDisplayName\",\n",
        "    # ta có thể trích xuất brand từ đó và chuyển sang giá trị số theo mapping:\n",
        "    extracted = extract_brand(example[\"productDisplayName\"], example[\"gender\"])\n",
        "    # Lưu ý: nếu không tìm thấy, extract_brand sẽ trả về token đầu tiên\n",
        "    # và mapping brand có thể đã được xây dựng từ dữ liệu ban đầu.\n",
        "    example[\"brand\"] = brand_map.get(extracted, -1)  # Nếu không có, đặt giá trị -1 (hoặc giá trị mặc định)\n",
        "    example[\"gender\"] = gender_map[example[\"gender\"]]\n",
        "    return example\n",
        "\n",
        "train_dataset = train_dataset.map(update_categorical)\n",
        "val_dataset = val_dataset.map(update_categorical)\n",
        "test_dataset = test_dataset.map(update_categorical)"
      ],
      "metadata": {
        "id": "qJrrSXiFxQhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo MinMaxScaler\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# Fit trên train dataset trước\n",
        "scaling_values_train = np.array([train_dataset[col] for col in [\"year\", \"price_in_vnd\"]]).T\n",
        "scaled_values_train = min_max_scaler.fit_transform(scaling_values_train)\n",
        "\n",
        "# Áp dụng MinMaxScaler đã fit cho val & test\n",
        "def scale_dataset(dataset, min_max_scaler):\n",
        "    scaling_values = np.array([dataset[col] for col in [\"year\", \"price_in_vnd\"]]).T\n",
        "    scaled_values = min_max_scaler.transform(scaling_values)  # Chỉ transform, không fit lại\n",
        "    return dataset.map(lambda x, idx: {'year': scaled_values[idx][0], 'price_in_vnd': scaled_values[idx][1]}, with_indices=True)\n",
        "\n",
        "train_dataset = scale_dataset(train_dataset, min_max_scaler)\n",
        "val_dataset = scale_dataset(val_dataset, min_max_scaler)\n",
        "test_dataset = scale_dataset(test_dataset, min_max_scaler)"
      ],
      "metadata": {
        "id": "DDSTYz9DxU4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "season_mapping = {'Spring': 0, 'Summer': 1, 'Fall': 2, 'Winter': 3}\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x: {'season': season_mapping[x['season']]})\n",
        "val_dataset = val_dataset.map(lambda x: {'season': season_mapping[x['season']]})\n",
        "test_dataset = test_dataset.map(lambda x: {'season': season_mapping[x['season']]})"
      ],
      "metadata": {
        "id": "Ie6ViRsfxYsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"gender\", \"masterCategory\", \"subCategory\", \"articleType\", \"baseColour\", \"season\", \"usage\", \"brand\"]:\n",
        "    unique_values = train_dataset.unique(col)\n",
        "    print(f\"Số lượng giá trị unique trong cột '{col}': {len(unique_values)}\")\n",
        "    print(f\"Giá trị unique: {unique_values}\")\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "OhGsoH95xa7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 BERT Tokenizer for Transformer"
      ],
      "metadata": {
        "id": "xw_CN7W7xccc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"productDisplayName\"], padding=\"max_length\", truncation=True, max_length=13)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "# Loại bỏ cột productDisplayName sau khi tokenized\n",
        "train_dataset = train_dataset.remove_columns([\"productDisplayName\"])\n",
        "val_dataset = val_dataset.remove_columns([\"productDisplayName\"])\n",
        "test_dataset = test_dataset.remove_columns([\"productDisplayName\"])\n",
        "train_dataset.features"
      ],
      "metadata": {
        "id": "2AfixmzfxfPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Preprocess Image"
      ],
      "metadata": {
        "id": "No0MMf_2xkKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]\n",
        "import psutil\n",
        "\n",
        "# Dung lượng RAM khả dụng và đã sử dụng\n",
        "total_memory = psutil.virtual_memory().total / (1024**3)  # GB\n",
        "used_memory = psutil.virtual_memory().used / (1024**3)  # GB\n",
        "available_memory = psutil.virtual_memory().available / (1024**3)  # GB\n",
        "\n",
        "print(f\"🖥️ Tổng RAM: {total_memory:.2f} GB\")\n",
        "print(f\"🚀 RAM đang dùng: {used_memory:.2f} GB\")\n",
        "print(f\"🔄 RAM khả dụng: {available_memory:.2f} GB\")"
      ],
      "metadata": {
        "id": "J5XR3lJMxiia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    gpu_memory_used = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    gpu_memory_free = gpu_memory_total - gpu_memory_used\n",
        "\n",
        "    print(f\"🖥️ Tổng bộ nhớ GPU: {gpu_memory_total:.2f} GB\")\n",
        "    print(f\"🚀 GPU đang dùng: {gpu_memory_used:.2f} GB\")\n",
        "    print(f\"🔄 GPU còn trống: {gpu_memory_free:.2f} GB\")\n",
        "else:\n",
        "    print(\"❌ Không có GPU!\")"
      ],
      "metadata": {
        "id": "SbY9MkKVxnBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "# Kiểm tra và chọn GPU nếu có\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load feature extractor của ViT\n",
        "from transformers import ViTFeatureExtractor\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "\n",
        "# Tạo transform chạy trên GPU\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
        "])\n",
        "\n",
        "# Hàm xử lý ảnh trên GPU\n",
        "def preprocess_function(batch):\n",
        "    processed_images = []\n",
        "\n",
        "    for img in batch[\"image\"]:\n",
        "        if isinstance(img, str):  # Nếu là đường dẫn, mở ảnh\n",
        "            pil_img = Image.open(img).convert(\"RGB\")\n",
        "        else:\n",
        "            pil_img = img.convert(\"RGB\")  # Đảm bảo là RGB\n",
        "\n",
        "        # Chuyển ảnh thành tensor và đẩy lên GPU\n",
        "        tensor_img = transform(pil_img).to(device)\n",
        "        processed_images.append(tensor_img)\n",
        "\n",
        "    # Chuyển list thành tensor batch trên GPU\n",
        "    batch[\"pixel_values\"] = torch.stack(processed_images)\n",
        "\n",
        "    return batch\n",
        "\n",
        "# Áp dụng preprocessing trên GPU\n",
        "train_dataset = train_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    batch_size=32,\n",
        "    num_proc=1,  # Giữ mức thấp vì đã chạy trên GPU\n",
        "    remove_columns=[\"image\"]\n",
        ").with_format(\"torch\")  # Chuyển dataset sang định dạng Torch"
      ],
      "metadata": {
        "id": "WmrS6Gesxpqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy một batch từ dataset để kiểm tra\n",
        "example_batch = next(iter(train_dataset))\n",
        "\n",
        "# Chuyển từng ảnh trong `pixel_values` thành tensor\n",
        "processed_pixel_values = [torch.tensor(img, dtype=torch.float32) for img in example_batch[\"pixel_values\"]]\n",
        "\n",
        "# Chuyển list thành batch tensor\n",
        "pixel_values = torch.stack(processed_pixel_values)\n",
        "\n",
        "# Kiểm tra kết quả\n",
        "print(\"Pixel Values Shape:\", pixel_values.shape)  # 🚀 Kỳ vọng: [batch_size, 3, 224, 224]\n",
        "print(\"Pixel Values dtype:\", pixel_values.dtype)  # 🚀 Kỳ vọng: torch.float32\n"
      ],
      "metadata": {
        "id": "_RyxHQRrxzdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = val_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    batch_size=32,\n",
        "    num_proc=1,\n",
        "    remove_columns=[\"image\"]\n",
        ").with_format(\"torch\")"
      ],
      "metadata": {
        "id": "cBkDMXFByG0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    batch_size=32,\n",
        "    num_proc=1,\n",
        "    remove_columns=[\"image\"]\n",
        ").with_format(\"torch\")"
      ],
      "metadata": {
        "id": "BOrsc3TfyJQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III.  Fine-tuning Model (ViT)"
      ],
      "metadata": {
        "id": "54iQoMh8yLnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_ram = psutil.virtual_memory().available\n",
        "cpu_count = psutil.cpu_count(logical=True)\n",
        "print(f\"Available RAM: {available_ram / (1024**3):.2f} GB\")\n",
        "print(f\"CPU count: {cpu_count}\")"
      ],
      "metadata": {
        "id": "aS-gJtKPyM7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTModel\n",
        "# --- 1. Load mô hình ViT pre-trained ở chế độ 8-bit ---\n",
        "# Sử dụng bitsandbytes để tải model ở định dạng 8-bit nhằm tiết kiệm bộ nhớ GPU\n",
        "vit_model = ViTModel.from_pretrained(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    # load_in_8bit=True,       # 8-bit quantization\n",
        "    device_map={\"\": 0}        # Tự động phân bổ mô hình trên GPU\n",
        ")"
      ],
      "metadata": {
        "id": "zIPL4jhUyPvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Xây dựng Mô Hình ViT Tùy Chỉnh (Multi-Task Learning)"
      ],
      "metadata": {
        "id": "HO2GgsCGyRqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomViTHierarchical(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vit_model,\n",
        "                 num_gender=5,\n",
        "                 num_master=7,\n",
        "                 num_usage=8,\n",
        "                 num_sub=45,\n",
        "                 num_article=142,\n",
        "                 num_base=46,\n",
        "                 num_brand=820):\n",
        "        super(CustomViTHierarchical, self).__init__()\n",
        "        self.vit = vit_model\n",
        "        hidden_size = self.vit.config.hidden_size\n",
        "\n",
        "        # Level 1\n",
        "        self.head1_gender = nn.Linear(hidden_size, num_gender)\n",
        "        self.head1_master = nn.Linear(hidden_size, num_master)\n",
        "        self.head1_usage  = nn.Linear(hidden_size, num_usage)\n",
        "        self.level1_dim = num_gender + num_master + num_usage\n",
        "\n",
        "        # Level 2\n",
        "        self.head2 = nn.Sequential(\n",
        "            nn.Linear(hidden_size + self.level1_dim, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_sub)\n",
        "        )\n",
        "        self.level2_dim = self.level1_dim + num_sub\n",
        "\n",
        "        # Level 3\n",
        "        self.head3 = nn.Sequential(\n",
        "            nn.Linear(hidden_size + self.level2_dim, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_article)\n",
        "        )\n",
        "        self.level3_dim = self.level2_dim + num_article\n",
        "\n",
        "        # Level 4\n",
        "        self.head4 = nn.Sequential(\n",
        "            nn.Linear(hidden_size + self.level3_dim, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_base + num_brand)\n",
        "        )\n",
        "        self.num_base = num_base\n",
        "        self.num_brand = num_brand\n",
        "\n",
        "    def forward(self, pixel_values, labels=None, **kwargs):\n",
        "        outputs = self.vit(pixel_values=pixel_values)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]  # (batch, hidden_size)\n",
        "\n",
        "        # Level 1\n",
        "        pred_gender = self.head1_gender(cls_output)\n",
        "        pred_master = self.head1_master(cls_output)\n",
        "        pred_usage  = self.head1_usage(cls_output)\n",
        "        level1_pred = torch.cat([pred_gender, pred_master, pred_usage], dim=1)\n",
        "\n",
        "        # Level 2\n",
        "        level2_input = torch.cat([cls_output, level1_pred], dim=1)\n",
        "        pred_sub = self.head2(level2_input)\n",
        "        level2_pred = torch.cat([level1_pred, pred_sub], dim=1)\n",
        "\n",
        "        # Level 3\n",
        "        level3_input = torch.cat([cls_output, level2_pred], dim=1)\n",
        "        pred_article = self.head3(level3_input)\n",
        "        level3_pred = torch.cat([level2_pred, pred_article], dim=1)\n",
        "\n",
        "        # Level 4\n",
        "        level4_input = torch.cat([cls_output, level3_pred], dim=1)\n",
        "        pred_base_brand = self.head4(level4_input)\n",
        "        pred_base = pred_base_brand[:, :self.num_base]\n",
        "        pred_brand = pred_base_brand[:, self.num_base:]\n",
        "\n",
        "        outputs_dict = {\n",
        "            \"gender\": pred_gender,\n",
        "            \"master\": pred_master,\n",
        "            \"usage\": pred_usage,\n",
        "            \"sub\": pred_sub,\n",
        "            \"article\": pred_article,\n",
        "            \"base\": pred_base,\n",
        "            \"brand\": pred_brand\n",
        "        }\n",
        "\n",
        "        # Nếu labels được cung cấp, tính loss cho từng task và cộng dồn\n",
        "        if labels is not None:\n",
        "            loss = 0\n",
        "            for key in labels:\n",
        "                # Giả sử các nhãn trong labels có cùng các key: \"gender\", \"master\", ...\n",
        "                loss += F.cross_entropy(outputs_dict[key], labels[key])\n",
        "            outputs_dict[\"loss\"] = loss\n",
        "\n",
        "        return outputs_dict"
      ],
      "metadata": {
        "id": "cPFLf5s0yTzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomViTHierarchical(vit_model)\n",
        "# Freeze tất cả tham số trong backbone ViT\n",
        "for param in vit_model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "8iwD6cN0yWWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Danh sách các module chứa 'attn' hoặc 'attention':\")\n",
        "for name, module in model.named_modules():\n",
        "    if 'attn' in name or 'attention' in name:\n",
        "        print(name)\n",
        "        for sub_name, sub_module in module.named_modules():\n",
        "            print(f\"  - {sub_name}\")\n",
        "from peft import LoraConfig, get_peft_model\n"
      ],
      "metadata": {
        "id": "NWz0pLrFyYrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Cấu hình và chèn LoRA vào mô hình ---\n",
        "# Chúng ta áp dụng LoRA vào các projection layers của phần attention trong backbone ViT.\n",
        "# Vì model của bạn có ViT được lưu trong attribute 'vit', nên tên các module sẽ có tiền tố 'vit.'.\n",
        "lora_config = LoraConfig(\n",
        "    r=16,                # Rank của ma trận low-rank\n",
        "    lora_alpha=32,       # Hệ số scaling cho LoRA\n",
        "    target_modules=[\n",
        "        \"query\",\n",
        "        \"key\",\n",
        "        \"value\",\n",
        "        \"dense\"\n",
        "    ],\n",
        "    lora_dropout=0.05,   # Tỉ lệ dropout cho LoRA\n",
        "    bias=\"none\",         # Không cập nhật bias\n",
        "    task_type=\"FEATURE_EXTRACTION\"  # Loại nhiệm vụ (điều chỉnh nếu cần)\n",
        ")\n",
        "# Chèn LoRA vào mô hình (freeze hầu hết tham số, chỉ cập nhật các tham số LoRA)\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "F_lJwE6oyah5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. In số lượng tham số trainable để xác nhận ---\n",
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    total_params = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"Trainable params: {trainable_params} || Total params: {total_params} || Trainable%: {100 * trainable_params / total_params:.2f}%\")\n",
        "\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "llvAbthIyfa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    metrics = {}\n",
        "    total_loss = 0.0\n",
        "    num_tasks = 0\n",
        "\n",
        "    # Giả sử các task có các key: \"gender\", \"master\", \"usage\", \"sub\", \"article\", \"base\", \"brand\"\n",
        "    for key in labels:\n",
        "        # Chuyển đổi nếu cần (đảm bảo là tensor)\n",
        "        task_logits = torch.tensor(logits[key]) if not torch.is_tensor(logits[key]) else logits[key]\n",
        "        task_labels = torch.tensor(labels[key]) if not torch.is_tensor(labels[key]) else labels[key]\n",
        "\n",
        "        # Tính loss cho task hiện tại\n",
        "        loss_val = F.cross_entropy(task_logits, task_labels, reduction=\"mean\")\n",
        "        total_loss += loss_val.item()\n",
        "        num_tasks += 1\n",
        "\n",
        "        # Tính accuracy và f1\n",
        "        pred_ids = torch.argmax(task_logits, dim=-1).cpu().numpy()\n",
        "        true_ids = task_labels.cpu().numpy()\n",
        "        acc = accuracy_score(true_ids, pred_ids)\n",
        "        f1 = f1_score(true_ids, pred_ids, average='weighted')\n",
        "\n",
        "        metrics[f\"{key}_accuracy\"] = acc\n",
        "        metrics[f\"{key}_f1\"] = f1\n",
        "\n",
        "    # Tính loss trung bình cho tất cả các task và trả về dưới key \"eval_loss\"\n",
        "    metrics[\"eval_loss\"] = total_loss / num_tasks if num_tasks > 0 else 0.0\n",
        "\n",
        "    # Tính trung bình các chỉ số accuracy và f1 nếu cần\n",
        "    acc_values = [v for k, v in metrics.items() if k.endswith('_accuracy')]\n",
        "    f1_values = [v for k, v in metrics.items() if k.endswith('_f1')]\n",
        "    metrics[\"eval_average_accuracy\"] = sum(acc_values) / len(acc_values) if acc_values else 0.0\n",
        "    metrics[\"eval_average_f1\"] = sum(f1_values) / len(f1_values) if f1_values else 0.0\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "oNwekVgcyhXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_test_dataset = test_dataset.select(range(10))\n",
        "predictions = trainer.predict(small_test_dataset)\n",
        "print(\"Predictions:\", predictions.metrics)"
      ],
      "metadata": {
        "id": "yJw7YOiMyn9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_eval_dataset = val_dataset.select(range(10))  # chọn 10 mẫu đầu tiên\n",
        "eval_metrics = trainer.evaluate(eval_dataset=small_eval_dataset)\n",
        "print(\"Eval metrics:\", eval_metrics)"
      ],
      "metadata": {
        "id": "YXhR7o4zylvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "\n",
        "def custom_compute_loss(model, inputs, num_items_in_batch):\n",
        "    # Lấy nhãn từ inputs\n",
        "    labels = {\n",
        "        \"gender\": inputs[\"gender\"],\n",
        "        \"master\": inputs[\"master\"],\n",
        "        \"usage\": inputs[\"usage\"],\n",
        "        \"sub\": inputs[\"sub\"],\n",
        "        \"article\": inputs[\"article\"],\n",
        "        \"base\": inputs[\"base\"],\n",
        "        \"brand\": inputs[\"brand\"],\n",
        "    }\n",
        "\n",
        "    # Gọi model với các inputs cần thiết\n",
        "    outputs = model(\n",
        "        pixel_values=inputs[\"pixel_values\"],\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        token_type_ids=inputs[\"token_type_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"]\n",
        "    )\n",
        "\n",
        "    # Tính loss cho từng task (sử dụng CrossEntropyLoss)\n",
        "    loss = 0\n",
        "    for key in labels:\n",
        "        loss += F.cross_entropy(outputs[key], labels[key])\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "74YPcD0Myo70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def data_collator(features):\n",
        "    # Vì các trường này đã ở dạng tensor, nên dùng torch.stack() thay vì torch.tensor()\n",
        "    input_ids = torch.stack([f[\"input_ids\"] for f in features])\n",
        "    token_type_ids = torch.stack([f[\"token_type_ids\"] for f in features])\n",
        "    attention_mask = torch.stack([f[\"attention_mask\"] for f in features])\n",
        "\n",
        "    # Ghép batch của ảnh\n",
        "    pixel_values = torch.stack([f[\"pixel_values\"].clone().detach().float() for f in features])\n",
        "\n",
        "    # Các nhãn thường là kiểu số nguyên nên dùng torch.tensor() là ổn\n",
        "    labels = {\n",
        "        \"gender\": torch.tensor([f[\"gender\"] for f in features], dtype=torch.long),\n",
        "        \"master\": torch.tensor([f[\"masterCategory\"] for f in features], dtype=torch.long),\n",
        "        \"usage\": torch.tensor([f[\"usage\"] for f in features], dtype=torch.long),\n",
        "        \"sub\": torch.tensor([f[\"subCategory\"] for f in features], dtype=torch.long),\n",
        "        \"article\": torch.tensor([f[\"articleType\"] for f in features], dtype=torch.long),\n",
        "        \"base\": torch.tensor([f[\"baseColour\"] for f in features], dtype=torch.long),\n",
        "        \"brand\": torch.tensor([f[\"brand\"] for f in features], dtype=torch.long),\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"pixel_values\": pixel_values,\n",
        "        \"input_ids\": input_ids,\n",
        "        \"token_type_ids\": token_type_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        **labels,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5NOEvtdlyrGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy một số mẫu từ train_dataset (ví dụ 5 mẫu)\n",
        "sample_features = [train_dataset[i] for i in range(5)]"
      ],
      "metadata": {
        "id": "gXM6yDOmytmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gọi hàm data_collator trên các mẫu đó\n",
        "batch = data_collator(sample_features)"
      ],
      "metadata": {
        "id": "jdnR8AbJyu1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In thông tin của từng key trong batch\n",
        "print(\"Các key có trong batch:\", list(batch.keys()))\n",
        "print(\"Pixel Values shape:\", batch[\"pixel_values\"].shape)\n",
        "print(\"Input IDs shape:\", batch[\"input_ids\"].shape)\n",
        "print(\"Token Type IDs shape:\", batch[\"token_type_ids\"].shape)\n",
        "print(\"Attention Mask shape:\", batch[\"attention_mask\"].shape)"
      ],
      "metadata": {
        "id": "TmXUzDxSywJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In shape của các nhãn\n",
        "for label_key in [\"gender\", \"master\", \"usage\", \"sub\", \"article\", \"base\", \"brand\"]:\n",
        "    print(f\"{label_key} shape:\", batch[label_key].shape)\n"
      ],
      "metadata": {
        "id": "VjBzHh9fyx5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit_hierarchical\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=1,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=1,  # Lưu mỗi epoch thay vì mỗi 500 step\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,  # ⚡️ Mixed Precision (Tăng tốc GPU)\n",
        "    load_best_model_at_end=True,\n",
        "    dataloader_num_workers=0,  # 🔥 Tắt multi-processing tránh lỗi CUDA fork\n",
        "    # metric_for_best_model=\"average_f1\",\n",
        "    remove_unused_columns=False,  # ⚠️ Quan trọng: tránh lỗi khi có nhiều feature\n",
        "    logging_first_step=True,\n",
        "    dataloader_pin_memory=False,\n",
        ")"
      ],
      "metadata": {
        "id": "_aLWdTgay0Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # Lấy num_items_in_batch từ kwargs nếu có, ngược lại lấy batch size\n",
        "        num_items_in_batch = kwargs.get(\"num_items_in_batch\", len(inputs[\"input_ids\"]))\n",
        "        # Tính loss bằng hàm custom_compute_loss mà bạn đã định nghĩa\n",
        "        loss = custom_compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
        "        if return_outputs:\n",
        "            return loss, None\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "epLE4hmty2l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTImageProcessor\n",
        "\n",
        "# model_name = \"google/vit-large-patch16-224\"\n",
        "processor = ViTImageProcessor.from_pretrained(\"google/vit-large-patch16-224\")\n",
        "processor\n",
        "# Khởi tạo CustomTrainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "KdQIQdMjy4RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "UvgX50B-y6pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = trainer.predict(test_dataset)\n",
        "print(outputs.metrics)"
      ],
      "metadata": {
        "id": "an2Rfb6My792"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu model và cấu hình\n",
        "model.save_pretrained(\"./my_finetuned_vit\")"
      ],
      "metadata": {
        "id": "qcKyGxoLy9f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nếu có tokenizer (ví dụ: BERT tokenizer)\n",
        "tokenizer.save_pretrained(\"./my_finetuned_vit\")\n",
        "\n",
        "from transformers import ViTModel, BertTokenizer\n",
        "\n",
        "model = ViTModel.from_pretrained(\"./my_finetuned_vit\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"./my_finetuned_vit\")\n"
      ],
      "metadata": {
        "id": "7fi6X1_Uy_B9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}